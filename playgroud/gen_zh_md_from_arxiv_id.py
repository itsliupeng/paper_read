


import argparse
from trafilatura import fetch_url, extract
import openai

# åˆå§‹åŒ–æœ¬åœ°éƒ¨ç½²çš„AIç¿»è¯‘å®¢æˆ·ç«¯
client = openai.Client(base_url="http://10.65.249.237:30000/v1", api_key="EMPTY")
    
# TRANSLATE_PROMPT = r"""
# è¯·å°†ä»¥ä¸‹ markdown æ–‡æ¡£å†…å®¹ä»è‹±æ–‡ç²¾ç¡®ç¿»è¯‘ä¸ºç®€ä½“ä¸­æ–‡, ä¿ç•™ markdown æ ¼å¼ï¼Œå¯¹äºé”™ä¹±çš„æ ¼å¼ç›´æ¥ä¸¢å¼ƒ
# """


TRANSLATE_PROMPT = r"""
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚å°†è‹±æ–‡å­¦æœ¯è®ºæ–‡çš„markdownå†…å®¹ç¿»è¯‘ä¸ºä¸­æ–‡ï¼š

**ç¿»è¯‘è¦æ±‚**
1. **ç²¾å‡†æ€§**
   - ä¿ç•™æ‰€æœ‰æŠ€æœ¯æœ¯è¯­ï¼ˆå¦‚mAPã€FPSã€ResNetç­‰ï¼‰ä¸ç¿»è¯‘
   - ä¿æŒæ•°å­¦å…¬å¼/æ–¹ç¨‹å®Œå…¨ä¸å˜ï¼ˆåŒ…æ‹¬LaTeXæ ¼å¼ï¼‰
   - ä¸¥æ ¼ä¿ç•™åŸæ–‡ä¸­çš„å¼•ç”¨æ ‡è®°ï¼ˆå¦‚[1][2][3]ï¼‰

2. **æ ¼å¼ä¿ç•™**
   - Tableï¼ˆè¡¨æ ¼ï¼‰ï¼šå®Œæ•´ä¿ç•™è¡¨æ ¼ç»“æ„å’Œè‹±æ–‡å†…å®¹
   - Figureï¼ˆå›¾ç‰‡ï¼‰ï¼šä¿ç•™"![Alt text]"æ ¼å¼çš„å›¾ç‰‡å£°æ˜
   - Algorithmï¼ˆç®—æ³•ï¼‰ï¼šä¿æŒä¼ªä»£ç ç»“æ„å’Œè‹±æ–‡æœ¯è¯­
   - Referenceï¼ˆå‚è€ƒæ–‡çŒ®ï¼‰ï¼šå®Œæ•´ä¿ç•™è¯¥ç« èŠ‚ï¼ŒåŒ…æ‹¬ç¼–å·å’Œè‹±æ–‡æ¡ç›®

3. **æ ¼å¼ä¿®å¤**
   - è‡ªåŠ¨çº æ­£ä»¥ä¸‹é—®é¢˜ï¼š
     * ä¸è§„èŒƒçš„æ ‡é¢˜å±‚çº§ï¼ˆç¡®ä¿#å·ä¸æ ‡é¢˜é—´æœ‰ç©ºæ ¼ï¼‰
     * ä¿®å¤æ–­è£‚çš„åˆ—è¡¨ç¬¦å·ï¼ˆä¿®æ­£é”™è¯¯çš„åˆ—è¡¨ç¼©è¿›ï¼‰
     * ç»Ÿä¸€ä»£ç å—å£°æ˜ï¼ˆç¡®ä¿```å‰åç©ºè¡Œï¼‰
   - æ— æ³•ä¿®å¤çš„å¤æ‚æ ¼å¼é—®é¢˜ç›´æ¥åˆ é™¤è€Œéä¿ç•™é”™è¯¯

4. **ç¿»è¯‘è´¨é‡**
   - å®ç°ä¸‰çº§è´¨é‡æ ‡å‡†ï¼š
     1. ä¿¡ï¼šå®Œæ•´ä¼ è¾¾åŸæ–‡è¯­ä¹‰ï¼ˆæ— ä¿¡æ¯ä¸¢å¤±/æ·»åŠ ï¼‰
     2. è¾¾ï¼šç¡®ä¿ä¸­æ–‡è¡¨è¿°ç¬¦åˆå­¦æœ¯è§„èŒƒï¼ˆä½¿ç”¨ä¸“ä¸šé¢†åŸŸæƒ¯ç”¨è¡¨è¾¾ï¼‰
     3. é›…ï¼šä¼˜åŒ–å¥å¼ç»“æ„ï¼ˆæ¶ˆé™¤ç¿»è¯‘è…”ï¼Œä¿æŒå­¦æœ¯ä¸¥è°¨æ€§ï¼‰

**å¤„ç†æµç¨‹**
1. åˆ†æ®µè§£æåŸå§‹markdownç»“æ„
2. é€‰æ‹©æ€§ç¿»è¯‘æ–‡æœ¬æ®µè½ï¼ˆè·³è¿‡è¡¨æ ¼/ç®—æ³•/å…¬å¼ç­‰æŒ‡å®šå†…å®¹ï¼‰
3. æ‰§è¡Œæ ¼å¼éªŒè¯å’Œè‡ªåŠ¨ä¿®æ­£
4. æœ€ç»ˆç»“æœè´¨é‡æ£€æŸ¥ï¼ˆæ ¼å¼å®Œæ•´æ€§+ç¿»è¯‘å‡†ç¡®æ€§ï¼‰
5. æœ€ååªå°†å®Œæ•´ç¿»è¯‘çš„å†…å®¹æ”¾å…¥{{}}å†…ï¼Œæ–¹ä¾¿ä¸‹ä¸€æ­¥æå–
"""

from concurrent.futures import ThreadPoolExecutor
import re

def split_markdown_by_headings(md_content):
    """æŒ‰æ ‡é¢˜å±‚çº§æ‹†åˆ†markdownæ–‡æ¡£ä¸ºæ›´ç»†ç²’åº¦çš„æ®µè½"""
    # åŒ¹é…ä»»æ„å±‚çº§çš„æ ‡é¢˜ï¼Œå¹¶æ™ºèƒ½åˆ†å‰²å†…å®¹
    pattern = r'(^#{1,6} .+?)(?=^#{1,6} |\Z)'
    sections = []
    
    # å…ˆæŒ‰é¡¶çº§æ ‡é¢˜åˆ†å‰²
    top_level = re.findall(pattern, md_content, flags=re.MULTILINE|re.DOTALL)
    
    for section in top_level:
        # å¯¹æ¯ä¸ªé¡¶çº§æ ‡é¢˜ä¸‹çš„å†…å®¹è¿›è¡ŒäºŒæ¬¡åˆ†å‰²
        sub_sections = re.split(r'\n(?=#{2,6} )', section)
        for sub in sub_sections:
            # å¯¹äºŒçº§æ ‡é¢˜ä¸‹çš„å†…å®¹è¿›è¡Œä¸‰æ¬¡åˆ†å‰²ï¼ˆå¦‚æœæœ‰ä¸‰çº§æ ‡é¢˜ï¼‰
            sub_sub = re.split(r'\n(?=#{3,6} )', sub)
            sections.extend(sub_sub)
    
    # è¿‡æ»¤ç©ºæ®µè½å¹¶æ ‡å‡†åŒ–ç©ºç™½
    return [s.strip() for s in sections if s.strip()]

def translate_section(section):
    """ç¿»è¯‘å•ä¸ªmarkdownæ®µè½"""
    try:
        response = client.chat.completions.create(
            model="default",
            messages=[
                {"role": "system", "content": TRANSLATE_PROMPT},
                {"role": "user", "content": section},
            ],
            temperature=0.5,
            max_tokens=128000,
        )
        trans_tex = response.choices[0].message.content
        if "</think>" in trans_tex:
            trans_tex = trans_tex.split('</think>')[-1]
        return trans_tex.strip()
    except Exception as e:
        print(f"âš ï¸ ç¿»è¯‘å¤±è´¥: {str(e)}")
        return section  # è¿”å›åŸæ–‡ä½œä¸ºé™çº§å¤„ç†

def translate_tex(tex):
    """å¹¶å‘ç¿»è¯‘markdownå†…å®¹"""
    sections = split_markdown_by_headings(tex)
    print(f"ğŸ”€ æ‹†åˆ†å‡º {len(sections)} ä¸ªç« èŠ‚è¿›è¡Œå¹¶å‘ç¿»è¯‘...")
    max_workers = max(len(sections), 100)
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = executor.map(translate_section, sections)
    
    # åˆå¹¶ç¿»è¯‘ç»“æœå¹¶ä¿ç•™åŸå§‹ç©ºç™½è¡Œç»“æ„
    return '\n\n'.join(futures)

def main():
    parser = argparse.ArgumentParser(
        description='å°†arXivè®ºæ–‡è½¬æ¢ä¸ºä¸­æ–‡Markdown',
        formatter_class=argparse.RawTextHelpFormatter,
        epilog='ç¤ºä¾‹:\n  python gen_zh_md_from_arxiv_id.py 2502.20622v1'
    )
    parser.add_argument('arxiv_id', type=str, help='arXivè®ºæ–‡ID (ä¾‹å¦‚: 2502.20622v1)')
    args = parser.parse_args()

    try:
        print(f"ğŸ”„ æ­£åœ¨å¤„ç† arXiv è®ºæ–‡ {args.arxiv_id}...")
        
        # é€šè¿‡arXiv HTMLé¡µé¢è·å–å¹¶æå–Markdownå†…å®¹
        url = f"https://arxiv.org/html/{args.arxiv_id}"
        print(f"ğŸŒ ä¸‹è½½é¡µé¢å†…å®¹: {url}")
        downloaded = fetch_url(url)
        
        if not downloaded:
            raise ValueError("æ— æ³•è·å–é¡µé¢å†…å®¹ï¼Œè¯·æ£€æŸ¥arXiv IDæ˜¯å¦æ­£ç¡®")

        print("ğŸ”§ æå–Markdownå†…å®¹...")
        markdown = extract(
            downloaded,
            output_format="markdown",
            include_links=False,
            include_tables=True,
            no_fallback=True
        )

        # ä¿å­˜åŸå§‹Markdown
        en_filename = f"{args.arxiv_id}.md"
        with open(en_filename, "w", encoding="utf-8") as f:
            f.write(markdown)
        print(f"âœ… åŸå§‹Markdownå·²ä¿å­˜è‡³: {en_filename}")

        # ç¿»è¯‘å¹¶ä¿å­˜ä¸­æ–‡ç‰ˆ
        print("ğŸˆµ ç¿»è¯‘å†…å®¹è‡³ä¸­æ–‡...")
        zh_markdown = translate_tex(markdown)
        
        zh_filename = f"{args.arxiv_id}_zh.md"
        with open(zh_filename, "w", encoding="utf-8") as f:
            f.write(zh_markdown)
        print(f"âœ… ä¸­æ–‡Markdownå·²ä¿å­˜è‡³: {zh_filename}")

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        exit(1)

if __name__ == "__main__":
    main()
