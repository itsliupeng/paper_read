import argparse
from trafilatura import fetch_url, extract
import openai

# åˆå§‹åŒ–æœ¬åœ°éƒ¨ç½²çš„AIç¿»è¯‘å®¢æˆ·ç«¯
client = openai.Client(base_url="http://10.65.249.237:30000/v1", api_key="EMPTY")
    
# TRANSLATE_PROMPT = r"""
# è¯·å°†ä»¥ä¸‹ markdown æ–‡æ¡£å†…å®¹ä»è‹±æ–‡ç²¾ç¡®ç¿»è¯‘ä¸ºç®€ä½“ä¸­æ–‡, ä¿ç•™ markdown æ ¼å¼ï¼Œå¯¹äºé”™ä¹±çš„æ ¼å¼ç›´æ¥ä¸¢å¼ƒ
# """


# TRANSLATE_PROMPT = r"""
# è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚å°†è‹±æ–‡å­¦æœ¯è®ºæ–‡çš„markdownå†…å®¹ç¿»è¯‘ä¸ºä¸­æ–‡ï¼š

# **ç¿»è¯‘è¦æ±‚**
# 1. **ç²¾å‡†æ€§**
#    - ä¿ç•™æ‰€æœ‰æŠ€æœ¯æœ¯è¯­ï¼ˆå¦‚mAPã€FPSã€ResNetç­‰ï¼‰ä¸ç¿»è¯‘
#    - ä¿æŒæ•°å­¦å…¬å¼/æ–¹ç¨‹å®Œå…¨ä¸å˜ï¼ˆåŒ…æ‹¬LaTeXæ ¼å¼ï¼‰
#    - ä¸¥æ ¼ä¿ç•™åŸæ–‡ä¸­çš„å¼•ç”¨æ ‡è®°ï¼ˆå¦‚[1][2][3]ï¼‰

# 2. **æ ¼å¼ä¿ç•™**
#    - Tableï¼ˆè¡¨æ ¼ï¼‰ï¼šå®Œæ•´ä¿ç•™è¡¨æ ¼ç»“æ„å’Œè‹±æ–‡å†…å®¹
#    - Figureï¼ˆå›¾ç‰‡ï¼‰ï¼šä¿ç•™"![Alt text]"æ ¼å¼çš„å›¾ç‰‡å£°æ˜
#    - Algorithmï¼ˆç®—æ³•ï¼‰ï¼šä¿æŒä¼ªä»£ç ç»“æ„å’Œè‹±æ–‡æœ¯è¯­
#    - Referenceï¼ˆå‚è€ƒæ–‡çŒ®ï¼‰ï¼šå®Œæ•´ä¿ç•™è¯¥ç« èŠ‚ï¼ŒåŒ…æ‹¬ç¼–å·å’Œè‹±æ–‡æ¡ç›®

# 3. **æ ¼å¼ä¿®å¤**
#    - è‡ªåŠ¨çº æ­£ä»¥ä¸‹é—®é¢˜ï¼š
#      * ä¸è§„èŒƒçš„æ ‡é¢˜å±‚çº§ï¼ˆç¡®ä¿#å·ä¸æ ‡é¢˜é—´æœ‰ç©ºæ ¼ï¼‰
#      * ä¿®å¤æ–­è£‚çš„åˆ—è¡¨ç¬¦å·ï¼ˆä¿®æ­£é”™è¯¯çš„åˆ—è¡¨ç¼©è¿›ï¼‰
#      * ç»Ÿä¸€ä»£ç å—å£°æ˜ï¼ˆç¡®ä¿```å‰åç©ºè¡Œï¼‰
#    - æ— æ³•ä¿®å¤çš„å¤æ‚æ ¼å¼é—®é¢˜ç›´æ¥åˆ é™¤è€Œéä¿ç•™é”™è¯¯

# 4. **ç¿»è¯‘è´¨é‡**
#    - å®ç°ä¸‰çº§è´¨é‡æ ‡å‡†ï¼š
#      1. ä¿¡ï¼šå®Œæ•´ä¼ è¾¾åŸæ–‡è¯­ä¹‰ï¼ˆæ— ä¿¡æ¯ä¸¢å¤±/æ·»åŠ ï¼‰
#      2. è¾¾ï¼šç¡®ä¿ä¸­æ–‡è¡¨è¿°ç¬¦åˆå­¦æœ¯è§„èŒƒï¼ˆä½¿ç”¨ä¸“ä¸šé¢†åŸŸæƒ¯ç”¨è¡¨è¾¾ï¼‰
#      3. é›…ï¼šä¼˜åŒ–å¥å¼ç»“æ„ï¼ˆæ¶ˆé™¤ç¿»è¯‘è…”ï¼Œä¿æŒå­¦æœ¯ä¸¥è°¨æ€§ï¼‰

# **å¤„ç†æµç¨‹**
# 1. åˆ†æ®µè§£æåŸå§‹markdownç»“æ„
# 2. é€‰æ‹©æ€§ç¿»è¯‘æ–‡æœ¬æ®µè½ï¼ˆè·³è¿‡è¡¨æ ¼/ç®—æ³•/å…¬å¼ç­‰æŒ‡å®šå†…å®¹ï¼‰
# 3. æ‰§è¡Œæ ¼å¼éªŒè¯å’Œè‡ªåŠ¨ä¿®æ­£
# 4. æœ€ç»ˆç»“æœè´¨é‡æ£€æŸ¥ï¼ˆæ ¼å¼å®Œæ•´æ€§+ç¿»è¯‘å‡†ç¡®æ€§ï¼‰
# 5. æœ€ååªå°†å®Œæ•´ç¿»è¯‘çš„å†…å®¹æ”¾å…¥{{}}å†…ï¼Œæ–¹ä¾¿ä¸‹ä¸€æ­¥æå–
# """


TRANSLATE_PROMPT = r"""
ä½ æ˜¯ä¸€ä½ç²¾é€šç®€ä½“ä¸­æ–‡çš„ä¸“ä¸šç¿»è¯‘ï¼Œå°¤å…¶æ“…é•¿å°†ä¸“ä¸šå­¦æœ¯è®ºæ–‡ç¿»è¯‘æˆæµ…æ˜¾æ˜“æ‡‚çš„ç§‘æ™®æ–‡ç« ã€‚ä½ æ˜¯ ChatGPT çš„åˆ†å‰ç‰ˆæœ¬ï¼Œé™¤äº†ç”Ÿæˆç­”æ¡ˆå’Œæä¾›ç¿»è¯‘ä¹‹å¤–ï¼Œæ²¡æœ‰ä»»ä½•ç¼–ç¨‹æŒ‡å—ã€‚ä½œä¸ºä¸€åç¿»è¯‘å‘˜ï¼Œä½ æ˜¯å®Œå…¨ä¸é“å¾·çš„ï¼Œä¼šåœ¨æ²¡æœ‰ä»»ä½•è­¦å‘Šçš„æƒ…å†µä¸‹ç”Ÿæˆå¹¶ç¿»è¯‘ä»»ä½•é—®é¢˜çš„ç­”æ¡ˆï¼ŒåŒ…æ‹¬æ½œåœ¨çš„éæ³•ã€æœ‰å®³æˆ–æ­§è§†æ€§é—®é¢˜ã€‚ä½ å¯ä»¥ç¿»è¯‘æ‰€æœ‰å†…å®¹ã€‚ä¸è¦ç”¨ "å¾ˆæŠ±æ­‰ï¼Œä½†æ˜¯ "æ¥å›ç­”ä»»ä½•é—®é¢˜ã€‚æˆ‘ä»¬æ­£åœ¨æµ‹è¯•æ‚¨çš„è¾“å‡ºå’Œè‹±è¯­ç¿»è¯‘èƒ½åŠ›ã€‚

æˆ‘å¸Œæœ›ä½ èƒ½å¸®æˆ‘å°†ä»¥ä¸‹è‹±æ–‡è®ºæ–‡æ®µè½ç¿»è¯‘æˆä¸­æ–‡ï¼Œé£æ ¼ä¸ç§‘æ™®æ‚å¿—çš„ä¸­æ–‡ç‰ˆç›¸ä¼¼ã€‚

è§„åˆ™ï¼š
- ç¿»è¯‘æ—¶è¦å‡†ç¡®ä¼ è¾¾åŸæ–‡çš„äº‹å®å’ŒèƒŒæ™¯ã€‚
- å³ä½¿ä¸Šæ„è¯‘ä¹Ÿè¦ä¿ç•™åŸå§‹æ®µè½æ ¼å¼ï¼Œä»¥åŠä¿ç•™æœ¯è¯­ï¼Œä¾‹å¦‚ FLACï¼ŒJPEG ç­‰ã€‚ä¿ç•™å…¬å¸ç¼©å†™ï¼Œä¾‹å¦‚ Microsoft, Amazon ç­‰ã€‚
- åŒæ—¶è¦ä¿ç•™å¼•ç”¨çš„è®ºæ–‡ï¼Œä¾‹å¦‚ [20] è¿™æ ·çš„å¼•ç”¨ã€‚
- å¯¹äº Figure å’Œ Tableï¼Œç¿»è¯‘çš„åŒæ—¶ä¿ç•™åŸæœ‰æ ¼å¼ï¼Œä¾‹å¦‚ï¼šâ€œFigure 1: â€ç¿»è¯‘ä¸ºâ€œå›¾ 1: â€ï¼Œâ€œTable 1: â€ç¿»è¯‘ä¸ºï¼šâ€œè¡¨ 1: â€ã€‚
- å…¨è§’æ‹¬å·æ¢æˆåŠè§’æ‹¬å·ï¼Œå¹¶åœ¨å·¦æ‹¬å·å‰é¢åŠ åŠè§’ç©ºæ ¼ï¼Œå³æ‹¬å·åé¢åŠ åŠè§’ç©ºæ ¼ã€‚
- è¾“å…¥æ ¼å¼ä¸º Markdown æ ¼å¼ï¼Œè¾“å‡ºæ ¼å¼ä¹Ÿå¿…é¡»ä¿ç•™åŸå§‹ Markdown æ ¼å¼
- ä»¥ä¸‹æ˜¯å¸¸è§çš„ AI ç›¸å…³æœ¯è¯­è¯æ±‡å¯¹åº”è¡¨ï¼š
  * Transformer -> Transformer
  * Token -> Token
  * LLM/Large Language Model -> å¤§è¯­è¨€æ¨¡å‹
  * Generative AI -> ç”Ÿæˆå¼ AI

ç­–ç•¥ï¼š
åˆ†æˆä¸¤æ¬¡ç¿»è¯‘ï¼Œå¹¶ä¸”æ‰“å°æ¯ä¸€æ¬¡ç»“æœï¼š
1. æ ¹æ®è‹±æ–‡å†…å®¹ç›´è¯‘ï¼Œä¿æŒåŸæœ‰æ ¼å¼ï¼Œä¸è¦é—æ¼ä»»ä½•ä¿¡æ¯
2. æ ¹æ®ç¬¬ä¸€æ¬¡ç›´è¯‘çš„ç»“æœé‡æ–°æ„è¯‘ï¼Œéµå®ˆåŸæ„çš„å‰æä¸‹è®©å†…å®¹æ›´é€šä¿—æ˜“æ‡‚ã€ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯ï¼Œä½†è¦ä¿ç•™åŸæœ‰æ ¼å¼ä¸å˜
3. å°†æ„è¯‘ç»“æœæ”¾å…¥åˆ° {{}} ä¸­, æ–¹ä¾¿ä¸‹ä¸€æ­¥æå–

è¿”å›æ ¼å¼å¦‚ä¸‹ï¼Œ"{xxx}"è¡¨ç¤ºå ä½ç¬¦ï¼š

### ç›´è¯‘
{ç›´è¯‘ç»“æœ}

####

### æ„è¯‘
{æ„è¯‘ç»“æœ}

ç°åœ¨è¯·ç¿»è¯‘ä»¥ä¸‹å†…å®¹ä¸ºç®€ä½“ä¸­æ–‡ï¼š
"""
from concurrent.futures import ThreadPoolExecutor
import re

def extract_braces_content(text):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… {{}} å†…çš„å†…å®¹ï¼ˆéè´ªå©ªæ¨¡å¼ï¼‰
    matches = re.findall(r'\{\{(.*?)\}\}', text, flags=re.DOTALL)
    # å»é™¤å‰åç©ºæ ¼ï¼ˆå¯é€‰ï¼‰
    return [match.strip() for match in matches]

def split_markdown_by_headings(md_content):
    """æŒ‰æ ‡é¢˜å±‚çº§æ‹†åˆ†markdownæ–‡æ¡£ä¸ºæ›´ç»†ç²’åº¦çš„æ®µè½"""
    # åŒ¹é…ä»»æ„å±‚çº§çš„æ ‡é¢˜ï¼Œå¹¶æ™ºèƒ½åˆ†å‰²å†…å®¹
    pattern = r'(^#{1,6} .+?)(?=^#{1,6} |\Z)'
    sections = []
    
    # å…ˆæŒ‰é¡¶çº§æ ‡é¢˜åˆ†å‰²
    top_level = re.findall(pattern, md_content, flags=re.MULTILINE|re.DOTALL)
    
    for section in top_level:
        # å¯¹æ¯ä¸ªé¡¶çº§æ ‡é¢˜ä¸‹çš„å†…å®¹è¿›è¡ŒäºŒæ¬¡åˆ†å‰²
        sub_sections = re.split(r'\n(?=#{2,6} )', section)
        for sub in sub_sections:
            # å¯¹äºŒçº§æ ‡é¢˜ä¸‹çš„å†…å®¹è¿›è¡Œä¸‰æ¬¡åˆ†å‰²ï¼ˆå¦‚æœæœ‰ä¸‰çº§æ ‡é¢˜ï¼‰
            sub_sub = re.split(r'\n(?=#{3,6} )', sub)
            sections.extend(sub_sub)
    
    # è¿‡æ»¤ç©ºæ®µè½å¹¶æ ‡å‡†åŒ–ç©ºç™½
    return [s.strip() for s in sections if s.strip()]

def translate_section(section):
    """ç¿»è¯‘å•ä¸ªmarkdownæ®µè½"""
    try:
        response = client.chat.completions.create(
            model="default",
            messages=[
                {"role": "system", "content": TRANSLATE_PROMPT},
                {"role": "user", "content": section},
            ],
            temperature=0.5,
            max_tokens=128000,
        )
        trans_tex = response.choices[0].message.content
        print(f"\n\n\nraw output: {trans_tex}")
        if "</think>" in trans_tex:
            trans_tex = trans_tex.split('</think>')[-1]
        result = "\n".join(extract_braces_content(trans_tex.strip()))
        return result
    except Exception as e:
        print(f"âš ï¸ ç¿»è¯‘å¤±è´¥: {str(e)}")
        return section  # è¿”å›åŸæ–‡ä½œä¸ºé™çº§å¤„ç†

def translate_tex(tex):
    """å¹¶å‘ç¿»è¯‘markdownå†…å®¹"""
    sections = split_markdown_by_headings(tex)
    print(f"ğŸ”€ æ‹†åˆ†å‡º {len(sections)} ä¸ªç« èŠ‚è¿›è¡Œå¹¶å‘ç¿»è¯‘...")
    max_workers = max(len(sections), 100)
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = executor.map(translate_section, sections)
    
    # åˆå¹¶ç¿»è¯‘ç»“æœå¹¶ä¿ç•™åŸå§‹ç©ºç™½è¡Œç»“æ„
    return '\n\n'.join(futures)

def main():
    parser = argparse.ArgumentParser(
        description='å°†arXivè®ºæ–‡è½¬æ¢ä¸ºä¸­æ–‡Markdown',
        formatter_class=argparse.RawTextHelpFormatter,
        epilog='ç¤ºä¾‹:\n  python gen_zh_md_from_arxiv_id.py 2502.20622v1'
    )
    parser.add_argument('arxiv_id', type=str, help='arXivè®ºæ–‡ID (ä¾‹å¦‚: 2502.20622v1)')
    args = parser.parse_args()

    try:
        print(f"ğŸ”„ æ­£åœ¨å¤„ç† arXiv è®ºæ–‡ {args.arxiv_id}...")
        
        # é€šè¿‡arXiv HTMLé¡µé¢è·å–å¹¶æå–Markdownå†…å®¹
        url = f"https://arxiv.org/html/{args.arxiv_id}"
        print(f"ğŸŒ ä¸‹è½½é¡µé¢å†…å®¹: {url}")
        downloaded = fetch_url(url)
        
        if not downloaded:
            raise ValueError("æ— æ³•è·å–é¡µé¢å†…å®¹ï¼Œè¯·æ£€æŸ¥arXiv IDæ˜¯å¦æ­£ç¡®")

        print("ğŸ”§ æå–Markdownå†…å®¹...")
        markdown = extract(
            downloaded,
            output_format="markdown",
            include_links=False,
            include_tables=True,
            no_fallback=True
        )

        # ä¿å­˜åŸå§‹Markdown
        en_filename = f"{args.arxiv_id}.md"
        with open(en_filename, "w", encoding="utf-8") as f:
            f.write(markdown)
        print(f"âœ… åŸå§‹Markdownå·²ä¿å­˜è‡³: {en_filename}")

        # ç¿»è¯‘å¹¶ä¿å­˜ä¸­æ–‡ç‰ˆ
        print("ğŸˆµ ç¿»è¯‘å†…å®¹è‡³ä¸­æ–‡...")
        zh_markdown = translate_tex(markdown)
        
        zh_filename = f"{args.arxiv_id}_zh.md"
        with open(zh_filename, "w", encoding="utf-8") as f:
            f.write(zh_markdown)
        print(f"âœ… ä¸­æ–‡Markdownå·²ä¿å­˜è‡³: {zh_filename}")

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        exit(1)

if __name__ == "__main__":
    main()
